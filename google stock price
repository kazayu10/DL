import numpy as np
import tensorflow as tf
import pandas as pd
import seaborn as sns 
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import SimpleRNN
from keras.layers import Dropout
%matplotlib inline

df = pd.read_csv("Google_Stock_Price_Train.csv")
print(df.head(3))

Training_Set = df.iloc[:,1:2]
print(Training_Set.head(2))
print("\n")
print(Training_Set.shape)

Training_Set = Training_Set.values

#Applying Transformation 
sc = MinMaxScaler(feature_range=(0, 1))
Train = sc.fit_transform(Training_Set)

X_Train = []
Y_Train = []
# Range should be fromm 60 Values to END 
for i in range(60, Train.shape[0]):   
    # X_Train 0-59 
    X_Train.append(Train[i-60:i,0])    
    # Y Would be 60 th Value based on past 60 Values 
    Y_Train.append(Train[i,0])
# Convert into Numpy Array
X_Train = np.array(X_Train)
Y_Train = np.array(Y_Train)
print(X_Train.shape)
print(Y_Train.shape)

# Shape should be Number of [Datapoints , Steps , features=1 )
# we convert into 3-d Vector 
X_Train = np.reshape(X_Train, newshape=(X_Train.shape[0], X_Train.shape[1], 1))

# Architecture of our Neural Network
regressor = Sequential()
regressor.add(SimpleRNN(units = 50, return_sequences = True, input_shape = (X_Train.shape[1], 1)))
regressor.add(Dropout(0.2))
regressor.add(SimpleRNN(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
regressor.add(SimpleRNN(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
regressor.add(SimpleRNN(units = 50))
regressor.add(Dropout(0.2))
# Adding the output layer
regressor.add(Dense(units = 1))
# Compiling the RNN
regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')
regressor.fit(X_Train, Y_Train, epochs = 60, batch_size = 32)

df1 = pd.read_csv('Google_Stock_Price_Test.csv')
df1.head(2)

Df_Total = pd.concat((df["Open"], df1["Open"]), axis=0)

# Preparing the testing input
inputs = Df_Total[len(Df_Total) - len(df1) - 60:].values
# We need to Reshape
inputs = inputs.reshape(-1,1)
# Normalize the Dataset
inputs = sc.transform(inputs)
X_test = []
for i in range(60, 80):
    X_test.append(inputs[i-60:i, 0])
# Convert into Numpy Array
X_test = np.array(X_test)
# Reshape before Passing to Network
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
# Pass to Model 
predicted_stock_price = regressor.predict(X_test)
# Do inverse Transformation to get Values 
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

# change the index to Date 
df1["Open"].plot()
plt.title("Actual Google Stock Price")
plt.grid(True)
plt.ylabel("Price in $")

Prediction = pd.DataFrame(data={
    "Date":df1["Date"].to_list(),
    "Open":df1["Open"],
    "Network Predicted":[x[0] for x in predicted_stock_price ]
})

Prediction.plot()

Prediction

regressor = Sequential()
# Adding the first LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_Train.shape[1], 1)))
regressor.add(Dropout(0.2))
# Adding a second LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
# Adding a third LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
# Adding a fourth LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))
# Adding the output layer
regressor.add(Dense(units = 1))
# Compiling the RNN
regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')
regressor.fit(X_Train, Y_Train, epochs = 100, batch_size = 32)

predicted_stock_price = regressor.predict(X_test)
# Do inverse Transformation to get Values 
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

Prediction = pd.DataFrame(data={
    "Date":df1["Date"].to_list(),
    "Open":df1["Open"],
    "Network Predicted":[x[0] for x in predicted_stock_price ]
})

Prediction.plot()

Prediction
